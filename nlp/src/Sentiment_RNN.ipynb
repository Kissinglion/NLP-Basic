{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.1.post2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchtext.data as data\n",
    "import torchtext.datasets as datasets\n",
    "import pickle\n",
    "#print (torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Text(nn.Module):\n",
    "    \n",
    "    def __init__(self, embed_num, class_num):\n",
    "        super(RNN_Text, self).__init__()\n",
    "        V = embed_num\n",
    "        C = class_num\n",
    "        H = 256\n",
    "        \n",
    "        self.embed = nn.Embedding(V, 100)\n",
    "        self.rnn = nn.LSTM(100,H, bidirectional = True)\n",
    "        self.out = nn.Linear(H*2, C)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)  # (N, W, D)\n",
    "        ##x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
    "        x,(_,__) = self.rnn( x, ( self.h, self.c ) )\n",
    "        \n",
    "        logit = self.out(x[-1])\n",
    "        return logit\n",
    "    def inithidden(self,b):\n",
    "        self.h = Variable(torch.randn(2, b, 256))\n",
    "        self.c = Variable(torch.randn(2, b, 256))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mydataset(data.Dataset):\n",
    "    @staticmethod\n",
    "    def sort_key(ex):\n",
    "        return len(ex.text)\n",
    "    def __init__(self, text_field, label_field, path=None, examples=None, **kwargs):\n",
    "        fields = [('text', text_field), ('label', label_field)]\n",
    "        if examples is None:\n",
    "            path = self.dirname if path is None else path\n",
    "            examples = []\n",
    "            for i,line in enumerate(open(path,'r',encoding='utf-8')):\n",
    "                if i==0:\n",
    "                    continue\n",
    "                line = line.strip().split('\\t')\n",
    "                txt = line[1].split(' ')\n",
    "                #txt= [ d.split('/')[0] for d in line[1].split(' ') ]\n",
    "                examples += [ data.Example.fromlist( [txt, line[2]],fields ) ]\n",
    "        super(mydataset, self).__init__(examples, fields, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21893"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_field = data.Field(fix_length=20)\n",
    "#text_field = data.Field()\n",
    "label_field = data.Field(sequential=False, batch_first = True, unk_token = None)\n",
    "\n",
    "train_data = mydataset(text_field,label_field,path='../nsm/small_ratings_train_tok.txt')\n",
    "\n",
    "test_data = mydataset(text_field,label_field,path='../nsm/small_ratings_test_tok.txt')\n",
    "\n",
    "text_field.build_vocab(train_data)\n",
    "label_field.build_vocab(train_data)\n",
    "\n",
    "train_iter, test_iter = data.Iterator.splits(\n",
    "                            (train_data, test_data), \n",
    "                            batch_sizes=(100, 1), repeat=False)#, device = -1)\n",
    "len(text_field.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN_Text(\n",
       "  (embed): Embedding(21893, 100)\n",
       "  (rnn): LSTM(100, 256, bidirectional=True)\n",
       "  (out): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = RNN_Text(len(text_field.vocab),2)\n",
    "optimizer = torch.optim.Adam(rnn.parameters())\n",
    "rnn.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch\n",
      "69.83460813760757\n",
      "1 epoch\n",
      "66.15904760360718\n",
      "2 epoch\n",
      "54.62819701433182\n",
      "3 epoch\n",
      "43.72859424352646\n",
      "4 epoch\n",
      "34.153479278087616\n",
      "5 epoch\n",
      "26.51490344852209\n",
      "6 epoch\n",
      "19.30791373550892\n",
      "7 epoch\n",
      "14.81022097915411\n",
      "8 epoch\n",
      "10.427546622231603\n",
      "9 epoch\n",
      "8.190892105922103\n",
      "10 epoch\n",
      "6.217248036991805\n",
      "11 epoch\n",
      "4.998983516357839\n",
      "12 epoch\n",
      "3.911643920233473\n",
      "13 epoch\n",
      "3.387961565516889\n",
      "14 epoch\n",
      "3.3510223287157714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:159: UserWarning: Couldn't retrieve source code for container of type RNN_Text. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(15):\n",
    "    z=0\n",
    "    totalloss = 0\n",
    "    for batch in train_iter:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        txt = batch.text\n",
    "        label = batch.label\n",
    "        #print (txt.size())\n",
    "        rnn.inithidden(txt.size(1))\n",
    "        \n",
    "        pred = rnn(txt)\n",
    "        #print(pred.size(), label.size())\n",
    "        #print(label)\n",
    "        loss = F.cross_entropy(pred, label)\n",
    "        totalloss += loss.data[0]\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(data,label)\n",
    "        \n",
    "    print(epoch,'epoch')  \n",
    "    print(totalloss)\n",
    "    \n",
    "torch.save(rnn,'model/rnn_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct :  77\n",
      "incorrect :  23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "incorrect = 0\n",
    "rnn.eval()\n",
    "for batch in test_iter:\n",
    "    txt = batch.text\n",
    "    label = batch.label\n",
    "    \n",
    "    rnn.inithidden(txt.size(1))\n",
    "    \n",
    "    pred = rnn(txt)\n",
    "    _,ans = torch.max(pred,dim=1)\n",
    "    \n",
    "    if ans.data[0] == label.data[0]:\n",
    "        correct += 1    \n",
    "    else:\n",
    "        incorrect += 1\n",
    "    \n",
    "print ('correct : ', correct)\n",
    "print ('incorrect : ', incorrect)\n",
    "print ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
